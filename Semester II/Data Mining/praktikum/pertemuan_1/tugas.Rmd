---
title: "PRAKTIKUM PENAMBANGAN DATA"
subtitle: "Tugas Praktikum I"
author: "Mohammad Rizka Fadhli 20921004"
institute: "Magister Sains Komputasi, ITB"
date: "17 Maret 2021"
output: 
  html_document:
   toc: true
   number_sections: true
   theme: readable
   highlight: espresso
   toc_float:
     collapse: false
   fig_caption: true
---

```{r, include=FALSE}
rm(list=ls())
```

# KETERANGAN

## Bahasa yang Digunakan

Pada praktikum ini, saya menggunakan bahasa __R__ versi `4.1.2`.

Beberapa _libraries_ yang digunakan antara lain:

1. `dplyr` untuk melakukan _data carpentry_. Saya akan menggunakan prinsip _tidy_ dengan memanfaatkan _pipe operator_ `%>%`.
1. `janitor` untuk merapikan penamaan atribut (kolom).
1. `caret` untuk melakukan _one hot encoding_ dan beberapa _scaling data_.
1. `pls` untuk melakukan regresi linear dengan PCA.

Selain itu, akan dibuat beberapa _custom function_ untuk memudahkan menjawab soal.

### Cek Apakah Libraries Sudah Installed

Pertama-tama saya akan coba cek terlebih dahulu apakah _libraries_ yang dibutuhkan sudah ter-_install_ atau tidak. Jika tidak, saya akan buat perintah agar __R__ meng-_install_-nya terlebih dahulu.

```{r}
paket = c("dplyr","janitor","caret","pls")
install.packages(setdiff(paket,rownames(installed.packages())))
```

### Memanggil _Libraries_

```{r,message = FALSE, warning = FALSE}
library(dplyr)
library(janitor)
library(caret)
library(pls)
```

## _Notebook_ atau _Markdown_

_Notebook_ atau _markdown_ ini ditulis memanfaatkan `library(rmarkdown)` dan di-_export_ ke dalam format `.html`.

# SOAL

## _Import_ Data dan _Preprocessing_

Muatlah data `melb.csv` dan lakukan _preprocessing_ berikut:

1. _Imputation_
2. _One hot encoding_
3. _Thresholding_ dan _binarizing_
4. _Scalling_ dan _normalizing_
5. _Oversampling_ atau _undersampling_

## _Dimension Reduction_ - PCA

Ekstrak dua _principal component_ dari `melb.csv` yang telah di-_preprocessing_. Lakukan _machine learning_ regresi untuk memprediksi `price` dan amati perbandingan _loss value_ sebelum dan setelah diekstrak menjadi komponen utama.

# JAWABAN DAN PEMBAHASAN

## Memanggil Data

Kita akan _import_ data `melb.csv` ke dalam _environment_ lalu mengubah nama atribut agar lebih rapi dengan cara:

```{r}
data =
   read.csv("melb.csv") %>%	# import data
   janitor::clean_names()	# merapikan nama atribut
```

Berikut adalah sampel 10 data teratas dari `melb.csv`:

```{r,echo=FALSE}
data %>% 
  head(10) %>% 
  DT::datatable()
```

<br>

Kita akan cek terlebih dahulu struktur data dan _summary_ singkatnya sebagai berikut:

```{r}
data %>% str()
data %>% summary()
```

<br>

Beberapa temuan yang kita dapatkan:

### Tipe Data

Kita lihat bahwa beberapa atribut memiliki tipe data yang berbeda-beda. Mulai dari _character_ hingga numerik.

Untuk beberapa atribut bertipe `character` yang __penting__, saya akan ubah menjadi tipe numerik dengan melakukan _one hot encoding_, yakni atribut:

1. `suburb`
1. `type`
1. `method`
1. `seller_g`
1. `council_area`
1. `regionname`

Sedangkan untuk data bertipe numerik, saya akan lakukan normalisasi dengan metode _mean absolute deviation_. 

$$\begin{matrix}
z = \frac{x - m}{s}, \text{ dengan:} \\
m = \frac{\sum{x}}{n} \\
s = \frac{|x - m|}{n}
\end{matrix}$$

Berikut adalah _function_-nya:

```{r}
normalize = function(var){
  n = length(var)           # menghitung n: berapa banyak data
  m = sum(var) / n          # hitung variabel m
  s = sum(abs(var - m))/n   # hitung variabel s
  z = (var - m)/s           # hitung z
  return(z)                 # output nilai z
}
```

<br>

### Data _Blank_ atau `NA`

Dari informasi di atas, ada tiga atribut yang memiliki nilai _blank_ atau `NA`, yakni:

1. Atribut `car` dengan `62` baris data `NA`. Pada atribut ini, saya akan _replace_ `NA` dengan nilai median dari atribut tersebut.
1. Atribut `building area` dengan `6450` baris data `NA`. Ini setara dengan $47.9 \%$ baris data kosong. Oleh karena itu, saya akan _drop_ atribut ini dari perhitungan regresi kelak.
1. Atribut `year_built` dengan `5375` baris data `NA`. Ini setara dengan $39.58 \%$ baris data kosong. Oleh karena itu, saya akan _drop_ atribut ini dari perhitungan regresi kelak.

## _Pre-Processing_

Pertama-tama saya akan melakukan _imputation_ terlebih dahulu untuk atribut `car` dengan _function_ berikut:

```{r}
median_car = median(data$car,na.rm = T)
```

### _Imputation_ `car`

Berikut ini adalah _imputation_ untuk data yang kita miliki:

```{r,message=FALSE,warning=FALSE}
data_clean =
  data %>% # memanggil data
  rowwise %>% 
  mutate(car = ifelse(is.na(car),median_car,car)) %>% # mengganti NA dg median
  ungroup() %>% 
  select(-year_built,-building_area) # menghapus dua atribut
```

Sekarang kita akan cek apakah masih ada nilai _blank_ atau `NA` pada data:

```{r}
data_clean %>% anyNA()
```

### Pemilihan Atribut

Saya juga akan _drop_ beberapa atribut yang dinilai tidak berpengaruh terhadap model regresi `price` kelak, yakni:

1. `address`
1. `date`
1. `postcode`
1. `lattitude`
1. `longtitude`

```{r}
data_clean = 
  data_clean %>% 
  select(-address,
         -date,
         -postcode,
         -lattitude,
         -longtitude)
```

### _One Hot Encoding_ Atribut _Character_

Selanjutnya kita akan ubah atribut _character_ menjadi numerik dengan mengubahnya menjadi bilangan biner setelah kita pecah terlebih dahulu menjadi banyak sesuai dengan isinya.

```{r,message=FALSE,warning=FALSE}
dummy = dummyVars("~.", data = data_clean)
data_clean_2 = data.frame(predict(dummy, newdata = data_clean))
```

### _Normalizing_ Atribut Numerik

Sekarang saya akan _normalize_ semua atribut numerik yang ada dengan _function_ yang sudah dibuat pada bagian sebelumnya.

```{r,message=FALSE,warning=FALSE}
data_clean_2 = 
  data_clean_2 %>%
  mutate(rooms = normalize(rooms),
         price = normalize(price),
         bedroom2 = normalize(bedroom2),
         bathroom =  normalize(bathroom),
         car = normalize(car),
         landsize = normalize(landsize),
         propertycount = normalize(propertycount))

```

## Membuat Model Regresi

Sekarang saya akan membuat model regresi dari `data_clean_2`. Pertama-tama saya akan pisah keseluruhan data menjadi `train_data` dan `test_data` secara random dengan proporsi `80-20`.

```{r}
# menyimpan price menjadi variabel baru bernama target
target = data_clean_2$price
# menghapus price dari data
data_clean_2$price = NULL

# set seed
set.seed(20921004)

# define proporsi untuk train dataset
proporsi = 80/100
train_p = nrow(data_clean_2) * proporsi

# random id untuk kebutuhan train dan test
id_train = sample(1:nrow(data_clean_2),
                  train_p,
                  replace = F)

# train dataset
target_train = target[id_train]
train_data = data_clean_2[id_train,]

# test dataset
target_test = target[-id_train]
test_data = data_clean_2[-id_train,]
```

### Model Regresi Linear Tanpa PCA

Sekarang kita akan membuat model regresi linear untuk memprediksi `price` dari `train_data`. Kemudian hasilnya akan kita hitung akurasinya dengan `test_data`. Saya akan gunakan _Mean Absolute Error_ (MAE) sebagai parameter _goodness of fit_ dari model.

```{r,message=FALSE,warning=FALSE}
# mempersiapkan data
reg_lin_data = cbind(train_data,target_train)
# membuat model regresi linear
model = lm(target_train ~ .,
           data = reg_lin_data)
```

<br>

Berikut adalah _summary_ dari model di atas:

```{r,message=FALSE,warning=FALSE}
summary(model)
```

<br>

Kita akan hitung MAE dari hasil model menggunakan `test_data` berikut ini:

```{r,message=FALSE,warning=FALSE}
# menghitung hasil prediksi dari test data
hasil_prediksi = predict(model,test_data)
# menghitung MAE hasil prediksi vs price pada test_data
mae = MAE(hasil_prediksi,target_test)
mae
```

<br>

Kita dapatkan MAE sebesar `r mae`.

### Model Regresi Linear dengan PCA

Sekarang saya akan membuat model regresi dengan menggunakan PCA.

```{r,message=FALSE,warning=FALSE}
model_2 = pcr(target_train ~ .,
              data = reg_lin_data,
              scale = F,
              validation = "CV")
model_2
```

Sekarang kita akan memilih berapa _principal components_ yang sebaiknya digunakan.

```{r}
model_2 %>% summary()
```

Terlihat bahwa semakin banyak _principal components_ yang dimasukkan, semakin tinggi nilai _variance explained_ tapi nilai yang paling optimal adalah saat _principal components_ $=2$ (menghasilkan nilai `RMSEP` tertinggi).

Oleh karena itu, saya akan membuat model hanya dengan 2 PC saja. Kita akan hitung MAE dari hasil model menggunakan `test_data` berikut ini: 

```{r,message=FALSE,warning=FALSE}
# menghitung hasil prediksi dari test data
hasil_prediksi_pca = predict(model_2,test_data,ncomp = 2)
# menghitung MAE hasil prediksi vs price pada test_data
mae_2 = MAE(hasil_prediksi_pca,target_test)
mae_2
```

